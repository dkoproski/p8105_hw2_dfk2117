---
title: "p8105_hw2_dfk2117"
output: "github_document"
date: "2023-09-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Required libraries
```{r, echo=FALSE}
library(tidyverse)
```


## Problem 1

### Wotrking with the politicians data 

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

df_politicians =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |> 
  mutate(
    president = case_when(
      prez_gop %in% c(1,2) ~ "gop",
      prez_dem == 1 ~ "dem",
    )
  ) |>  
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -prez_gop, -prez_dem, -day)
```

### Working with the S&P data

```{r}
df_snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv", col_types = cols(date = col_date(format = "%m/%d/%y"))) |> 
  janitor::clean_names() |> 
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |> 
    mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close)

## note I did this one very wrong so I redid it using the answer key code
```

### Unemployment data

```{r}
df_unemployment =
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

### merging datasets

```{r}
df_538 =
  left_join(df_politicians, df_snp) |>
  left_join(x = _, y = df_unemployment)
```


## Problem 2 

### Working with the data
```{r}
df_mr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Mr_Trash") |> 
  mutate(year = as.numeric(year))


df_pr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 2) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Prof_Trash") |> 
  mutate(year = as.numeric(year))

df_gw_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 4) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Gwynnda") |> 
  mutate(year = as.numeric(year))

df_all_wheels = 
  bind_rows(df_gw_trash, df_mr_trash, df_pr_trash) |> 
  relocate(homes_powered) |> 
  relocate(dumpster) |> 
  relocate(trash_wheel)
  

```

### Descriptions
  Each of these three datasets contained a month, year and date variable (yyyy/mm/dd). They also contained a dumpster number variable and another two variables representing the amount of trash (in tons) and the volume of the trash (cubic yards) respectively. Each trash wheel also had counts of how many of a certain type of trash was picked up on that date. For Mr. Trash Wheel, this included Plastic Bottles, Polystyrene, Cigarette Butts, Glass Bottles, Plastic Bags, Sports Balls and Wrappers. Professor Trash Wheel's data included all of these same counts except for the Sports Balls count. Gwynda only included 5 of the counts: Plastic Bottles, Polystyrene, Cigarette Butts Plastic Bags and Wrappers (which was empty). Finally, all 3 datasets contained a `homes_powered` variable which was incomplete and not calculated in many instances.
  The resulting dataset contains all of the variables that the previous three contained, but now has a variable that labels which trash wheel the data comes from as well as the edited `homes_powered` variable that I made. There are 747 observations in `df_all_wheels`, which makes sense since there are 547, 106 and 94 observations in `df_mr_trash`, `df_gw_trash` and `df_prof_trash` respectively. 
  I used the `mutate()` function on each individual dataset to create a variable named `trash_wheel` which contains the names of each trash wheel (`mr_trash`, `prof_trash` and `gwynda`). I also used the `mutate()` function to make the `homes_powered` variable the weight of trash in tons times 500 over 30 (which is how the variable was described in the xslx file). For example, the 1.69 tons of trash collected by Mr. Trash Wheel on July, 29, 2022 in dumpster 547 powered `(1.69*500)/30` = 28.167 homes.
    I considered removing the counts of trash items that did not overlap in all 3 datasets, but I decided to leave them in for completeness. I merged the datasets using the `bind_rows()` function and then used the relocate function to move variables to the front.
  We can calculate the total weight of trash collected by professor trash wheel using the following code (note I had to do something a bit funky I found on stackoverflow at the end because R wasn't printing out any decimals):
```{r}
tw_ptrash = df_pr_trash |> 
  summarise(sum(weight_tons))

  print(sprintf("%.2f", tw_ptrash))
```
  Next, we can calculate the weight of trash collected by Gwynda in July 2021 using this code which filters out the month "july" in the year "2021" and then finds the sum of the trash collected:
```{r}
df_gw_trash |> 
  filter(month == "July", year == 2021) |> 
  summarise(sum(weight_tons))
```


## Problem 3

### Working with baseline data

```{r}
df_baseline_mci =
  read_csv("data/data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |> 
  mutate(apoe4 =
    case_when(
      apoe4 == 1 ~ "carrier",
      apoe4 == 0 ~ "non-carrier")
    ) |> 
  mutate(sex =
    case_when(
      sex == 1 ~ "male",
      sex == 0 ~ "female")
    ) |> 
  filter(current_age < age_at_onset | age_at_onset != ".") |> 
  mutate(age_at_onset = 
           as.numeric(
               age_at_onset)
             )
```
  During the import process, the first row needed to be removed as the names of each individual variable were being treated as an individual. I did this using `skip = 1` in the `read_csv()` function. 
  Based on the dataset, 483 were recruited and of those, 93 developed mci. The mean baseline age is 65.5 years and the code that gives it is:

```{r}
df_baseline_mci |> 
  summarise(mean(current_age))
```

  Further, 0.666 or 66.6% of females in the baseline study are carriers of apoe4. The code for this result is below. To do this, I summed up the number of female carriers and total females using the `summarise()` and `sum()` functions. I then created a new temporary variable using `mutate()` called `f_carrier_ratio` which `female_carriers` divided by `total_females`. Finally, I used the `pull()` function to print the new variable.

```{r}
df_baseline_mci |> 
  summarise(
    total_females = sum(sex == "female"),
    female_carriers = sum(sex == "female" & apoe4 == "carrier")) |> 
  mutate(f_carrier_ratio = female_carriers / total_females) |> 
  pull(f_carrier_ratio)
```

### Working with the amyloid data

```{r}
df_amyloid_mci =
  read_csv("data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |> 
  rename(id = study_id, 
         year_0 = baseline, 
         year_2 = time_2, 
         year_4 = time_4, 
         year_6 = time_6, 
         year_8 = time_8)
```

I also needed to excise the first row of the data while importing using `skip = 1`. I made a copy and removed the extraneous row before importing. I used the `rename()` function to rename the `study_id` variable to `id` which will make it easier to compare with `df_baseline_mci`

### Comparing the two datasets

```{r}
## only in baseline
df_only_baseline = 
  anti_join(df_baseline_mci, df_amyloid_mci)

## only in amyloid
df_only_amyloid = 
  anti_join(df_amyloid_mci, df_baseline_mci)


```



```{r}
df_baseline_amyloid = 
  inner_join(df_baseline_mci, df_amyloid_mci)
```

I used the `inner_join()` function to join `df_amyloid_mci` and `df_baseline_mci` by the variable `id`. Based on the resulting 94x11 tibble, it appears that 90 of the participants are shared between the two datasets (have the same value in the `id` column). The resulting dataset contains all variables from both `df_amyloid_mci` and `df_baseline_mci` and all matching observations.

```{r}
df_baseline_amyloid |> 
  write.csv("df_baseline_amyloid.csv")
```



Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.





