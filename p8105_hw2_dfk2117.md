p8105_hw2_dfk2117
================
2023-09-27

## Required libraries

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## Problem 1

### Wotrking with the politicians data

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

df_politicians =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |> 
  mutate(
    president = case_when(
      prez_gop %in% c(1,2) ~ "gop",
      prez_dem == 1 ~ "dem",
    )
  ) |>  
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -prez_gop, -prez_dem, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

### Working with the S&P data

``` r
df_snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv", col_types = cols(date = col_date(format = "%m/%d/%y"))) |> 
  janitor::clean_names() |> 
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |> 
    mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close)
```

    ## Joining with `by = join_by(month_num)`

``` r
## note I did this one very wrong so I redid it using the answer key 
```

### Working with unemployment data

``` r
df_unemployment =
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

### Merging datasets

``` r
df_538 =
  left_join(df_politicians, df_snp) |>
  left_join(x = _, y = df_unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

The `df_politicians` dataset contains contains 822 observations and 11
columns corresponding to `year`, `month`, `month_num` (month as numeric)
count of `gov_gop`, count of `sen_gop`, count of `rep_gop` and
corresponding variables for democrats. It also contains the `presedent`
variable I made which returns `dem` for `prez_dem == 1` and `gop` for
`prez_gop %in% c(1,2)`. This is because a number of the observations had
a 2 in the `prez_gop` column. The remaining column is just an
abbrevation for month (`month_abb`).

`df_snp` was trimmed to contain 787 observations of 3 columns: `year`,
`month` and `close`. Using `separate()` and `mutate()`, the original
data variable was separated, the `year` variable was created in 4 digit
format, the `month` variable was changed to show the month name and the
`day` variable was excised.

The resulting `df_unemployment` has 816 observations and 3 columns
representing the variables `Year`, `month` and `unemployment` (as a
percent). `pivot_longer()` was used to collapse the original month
variables into a single `month` variable and each of the corresponsing
unemployments into a single `unemployment` variable making the dataset
much more tidy.

Finally, `left_join` was used twice to create the resulting `df_538`
which has all 3 of the aforementioned datasets together as one. This
dataset has 822 observations and 13 columns which are a combination of
those in the `df_unemployment`, `df_politicians` and `df_snp`.

## Problem 2

### Working with the data

``` r
df_mr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Mr_Trash") |> 
  mutate(year = as.numeric(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
df_pr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 2) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Prof_Trash") |> 
  mutate(year = as.numeric(year))

df_gw_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 4) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Gwynnda") |> 
  mutate(year = as.numeric(year))

df_all_wheels = 
  bind_rows(df_gw_trash, df_mr_trash, df_pr_trash) |> 
  relocate(homes_powered) |> 
  relocate(dumpster) |> 
  relocate(trash_wheel)
```

### Descriptions

Each of these three datasets contained a month, year and date variable
(yyyy/mm/dd). They also contained a dumpster number variable and another
two variables representing the amount of trash (in tons) and the volume
of the trash (cubic yards) respectively. Each trash wheel also had
counts of how many of a certain type of trash was picked up on that
date. For Mr. Trash Wheel, this included Plastic Bottles, Polystyrene,
Cigarette Butts, Glass Bottles, Plastic Bags, Sports Balls and Wrappers.
Professor Trash Wheel’s data included all of these same counts except
for the Sports Balls count. Gwynda only included 5 of the counts:
Plastic Bottles, Polystyrene, Cigarette Butts Plastic Bags and Wrappers
(which was empty). Finally, all 3 datasets contained a `homes_powered`
variable which was incomplete and not calculated in many instances. The
resulting dataset contains all of the variables that the previous three
contained, but now has a variable that labels which trash wheel the data
comes from as well as the edited `homes_powered` variable that I made.
There are 747 observations in `df_all_wheels`, which makes sense since
there are 574, 155 and 106 observations in `df_mr_trash`, `df_gw_trash`
and `df_prof_trash` respectively.

I used the `mutate()` function on each individual dataset to create a
variable named `trash_wheel` which contains the names of each trash
wheel (`mr_trash`, `prof_trash` and `gwynda`). I also used the
`mutate()` function to make the `homes_powered` variable the weight of
trash in tons times 500 over 30 (which is how the variable was described
in the xslx file). For example, the 1.69 tons of trash collected by
Mr. Trash Wheel on July, 29, 2022 in dumpster 547 powered
`(1.69*500)/30` = 28.167 homes.

I considered removing the counts of trash items that did not overlap in
all 3 datasets, but I decided to leave them in for completeness. I
merged the datasets using the `bind_rows()` function and then used the
relocate function to move variables to the front.

We can calculate the total weight of trash collected by professor trash
wheel using the following code (note I had to do something a bit funky I
found on stackoverflow at the end because R wasn’t printing out any
decimals):

``` r
tw_ptrash = df_pr_trash |> 
  summarise(sum(weight_tons))

  print(sprintf("%.2f", tw_ptrash))
```

    ## [1] "216.26"

Next, we can calculate the number of cigarette butts collected by Gwynda
in July 2021 using this code which filters out the month “july” in the
year “2021” and then finds the sum of the cigarette butts collected:

``` r
df_gw_trash |> 
  filter(month == "July", year == 2021) |> 
  summarise(sum(cigarette_butts))
```

    ## # A tibble: 1 × 1
    ##   `sum(cigarette_butts)`
    ##                    <dbl>
    ## 1                  16300

## Problem 3

### Working with baseline data

``` r
df_baseline_mci =
  read_csv("data/data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |> 
  mutate(apoe4 =
    case_when(
      apoe4 == 1 ~ "carrier",
      apoe4 == 0 ~ "non-carrier")
    ) |> 
  mutate(sex =
    case_when(
      sex == 1 ~ "male",
      sex == 0 ~ "female")
    ) |> 
  mutate(age_at_onset = 
           as.numeric(
               age_at_onset)
             ) |> 
  filter((current_age < age_at_onset) | is.na(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `age_at_onset = as.numeric(age_at_onset)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

During the import process, the first row needed to be removed as the
names of each individual variable were being treated as an individual. I
did this using `skip = 1` in the `read_csv()` function.

Based on the dataset, 483 were recruited and of those, we retained 479
of them and removed 4. 71 individuals developed mci. The mean baseline
age is 65 years and the code that gives it is:

``` r
df_baseline_mci |> 
  summarise(mean(current_age))
```

    ## # A tibble: 1 × 1
    ##   `mean(current_age)`
    ##                 <dbl>
    ## 1                65.0

Further, 0.3 or 30% (63 out of 210) of females in the baseline study are
carriers of apoe4. The code for this result is below. To do this, I
summed up the number of female carriers and total females using the
`summarise()` and `sum()` functions. I then created a new temporary
variable using `mutate()` called `f_carrier_ratio` which
`female_carriers` divided by `total_females`. Finally, I used the
`pull()` function to print the new variable.

``` r
df_baseline_mci |> 
  summarise(
    total_females = sum(sex == "female"),
    female_carriers = sum(sex == "female" & apoe4 == "carrier")) |> 
  mutate(f_carrier_ratio = female_carriers / total_females) |> 
  pull(f_carrier_ratio)
```

    ## [1] 0.3

### Working with the amyloid data

``` r
df_amyloid_mci =
  read_csv("data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |> 
  rename(id = study_id, 
         year_0 = baseline, 
         year_2 = time_2, 
         year_4 = time_4, 
         year_6 = time_6, 
         year_8 = time_8) |> 
  pivot_longer(
    year_0:year_8,
    names_to = "time_interval",
    values_to = "biomarker"
  )
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I also needed to excise the first row of the data while importing using
`skip = 1`. I made a copy and removed the extraneous row before
importing. I used the `rename()` function to rename the `study_id`
variable to `id` which will make it easier to compare with
`df_baseline_mci` I also renamed all of the time points to more
accurately convey what the time frame was. Finally, I used
`pivot_longer()` to make a new variable called `time_interval` which
contains all of time variables that I renamed earlier. I also used
`pivot_longer()` to make a `biomarker` variable that contains each of
the time intervals’ biomarker values.

### Comparing the two datasets

Using `anti_join()` and the `distinct()` function on the `id` variable
and then counting the number of remaining rows with `nrow()`, we can
count the number of unique ID’s in only the baseline dataset.There are 8
unique ids only in the baseline set.

``` r
## only in baseline
count_only_baseline = 
  anti_join(df_baseline_mci, df_amyloid_mci) |> 
  distinct(id) |> 
  nrow()
```

    ## Joining with `by = join_by(id)`

``` r
count_only_baseline
```

    ## [1] 8

The same exact process can be used for the amyloid dataset, and we see
that there are 16 unique ids in the amyloid dataset that are not in the
baseline data.

``` r
## only in amyloid
count_only_amyloid = 
  anti_join(df_amyloid_mci, df_baseline_mci) |> 
  distinct(id) |> 
  nrow()
```

    ## Joining with `by = join_by(id)`

``` r
count_only_amyloid
```

    ## [1] 16

### Merging the two datasets

``` r
df_baseline_amyloid = 
  inner_join(df_baseline_mci, df_amyloid_mci) 
```

    ## Joining with `by = join_by(id)`

``` r
count_baseline_amyloid = 
  df_baseline_amyloid |> 
    distinct(id) |> 
    nrow()

count_baseline_amyloid
```

    ## [1] 471

I used the `inner_join()` function to join `df_amyloid_mci` and
`df_baseline_mci` by the variable `id`. The result is a 2355x8 tibble,
which makes sense as a quick calculation of the count of the unique IDs
reveals that there are 471 unique IDs multiplied by the 5 time periods
(which were combined into one column earlier) gives 2355 rows.
Furthermore, the 471 IDs makes sense given the fact that 8 of the
baseline ID’s were not present in the amyloid dataset, leading to
479-8=471 remaining in the `df_baseline_amyloid` dataset. The data frame
has the exact same columns that were in the `df_baseline_mci` and
`df_amyloid_mci` dataset.

### Saving the final dataset to CSV

``` r
df_baseline_amyloid |> 
  write_csv("df_baseline_amyloid.csv")
```
