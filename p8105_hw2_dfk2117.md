p8105_hw2_dfk2117
================
2023-09-27

## Required libraries

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## Problem 1

### Wotrking with the politicians data

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

df_politicians =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |> 
  mutate(
    president = case_when(
      prez_gop %in% c(1,2) ~ "gop",
      prez_dem == 1 ~ "dem",
    )
  ) |>  
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -prez_gop, -prez_dem, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

### Working with the S&P data

``` r
df_snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv", col_types = cols(date = col_date(format = "%m/%d/%y"))) |> 
  janitor::clean_names() |> 
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |> 
    mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close)
```

    ## Joining with `by = join_by(month_num)`

``` r
## note I did this one very wrong so I redid it using the answer key code
```

### Unemployment data

``` r
df_unemployment =
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

### merging datasets

``` r
df_538 =
  left_join(df_politicians, df_snp) |>
  left_join(x = _, y = df_unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

## Problem 2

### Working with the data

``` r
df_mr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Mr_Trash") |> 
  mutate(year = as.numeric(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
df_pr_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 2) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Prof_Trash") |> 
  mutate(year = as.numeric(year))

df_gw_trash =
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 4) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = ((weight_tons * 500)/30)) |> 
  mutate(trash_wheel = "Gwynnda") |> 
  mutate(year = as.numeric(year))

df_all_wheels = 
  bind_rows(df_gw_trash, df_mr_trash, df_pr_trash) |> 
  relocate(homes_powered) |> 
  relocate(dumpster) |> 
  relocate(trash_wheel)
```

### Descriptions

Each of these three datasets contained a month, year and date variable
(yyyy/mm/dd). They also contained a dumpster number variable and another
two variables representing the amount of trash (in tons) and the volume
of the trash (cubic yards) respectively. Each trash wheel also had
counts of how many of a certain type of trash was picked up on that
date. For Mr. Trash Wheel, this included Plastic Bottles, Polystyrene,
Cigarette Butts, Glass Bottles, Plastic Bags, Sports Balls and Wrappers.
Professor Trash Wheel’s data included all of these same counts except
for the Sports Balls count. Gwynda only included 5 of the counts:
Plastic Bottles, Polystyrene, Cigarette Butts Plastic Bags and Wrappers
(which was empty). Finally, all 3 datasets contained a `homes_powered`
variable which was incomplete and not calculated in many instances. The
resulting dataset contains all of the variables that the previous three
contained, but now has a variable that labels which trash wheel the data
comes from as well as the edited `homes_powered` variable that I made.
There are 747 observations in `df_all_wheels`, which makes sense since
there are 547, 106 and 94 observations in `df_mr_trash`, `df_gw_trash`
and `df_prof_trash` respectively. I used the `mutate()` function on each
individual dataset to create a variable named `trash_wheel` which
contains the names of each trash wheel (`mr_trash`, `prof_trash` and
`gwynda`). I also used the `mutate()` function to make the
`homes_powered` variable the weight of trash in tons times 500 over 30
(which is how the variable was described in the xslx file). For example,
the 1.69 tons of trash collected by Mr. Trash Wheel on July, 29, 2022 in
dumpster 547 powered `(1.69*500)/30` = 28.167 homes. I considered
removing the counts of trash items that did not overlap in all 3
datasets, but I decided to leave them in for completeness. I merged the
datasets using the `bind_rows()` function and then used the relocate
function to move variables to the front. We can calculate the total
weight of trash collected by professor trash wheel using the following
code (note I had to do something a bit funky I found on stackoverflow at
the end because R wasn’t printing out any decimals):

``` r
tw_ptrash = df_pr_trash |> 
  summarise(sum(weight_tons))

  print(sprintf("%.2f", tw_ptrash))
```

    ## [1] "216.26"

Next, we can calculate the weight of trash collected by Gwynda in July
2021 using this code which filters out the month “july” in the year
“2021” and then finds the sum of the trash collected:

``` r
df_gw_trash |> 
  filter(month == "July", year == 2021) |> 
  summarise(sum(weight_tons))
```

    ## # A tibble: 1 × 1
    ##   `sum(weight_tons)`
    ##                <dbl>
    ## 1                8.1

## Problem 3

### Working with baseline data

``` r
df_baseline_mci =
  read_csv("data/data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |> 
  mutate(apoe4 =
    case_when(
      apoe4 == 1 ~ "carrier",
      apoe4 == 0 ~ "non-carrier")
    ) |> 
  mutate(sex =
    case_when(
      sex == 1 ~ "male",
      sex == 0 ~ "female")
    ) |> 
  filter(current_age < age_at_onset | age_at_onset != ".") |> 
  mutate(age_at_onset = 
           as.numeric(
               age_at_onset)
             )
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

During the import process, the first row needed to be removed as the
names of each individual variable were being treated as an individual. I
did this using `skip = 1` in the `read_csv()` function. Based on the
dataset, 483 were recruited and of those, 93 developed mci. The mean
baseline age is 65.5 years and the code that gives it is:

``` r
df_baseline_mci |> 
  summarise(mean(current_age))
```

    ## # A tibble: 1 × 1
    ##   `mean(current_age)`
    ##                 <dbl>
    ## 1                65.6

Further, 0.666 or 66.6% of females in the baseline study are carriers of
apoe4. The code for this result is below. To do this, I summed up the
number of female carriers and total females using the `summarise()` and
`sum()` functions. I then created a new temporary variable using
`mutate()` called `f_carrier_ratio` which `female_carriers` divided by
`total_females`. Finally, I used the `pull()` function to print the new
variable.

``` r
df_baseline_mci |> 
  summarise(
    total_females = sum(sex == "female"),
    female_carriers = sum(sex == "female" & apoe4 == "carrier")) |> 
  mutate(f_carrier_ratio = female_carriers / total_females) |> 
  pull(f_carrier_ratio)
```

    ## [1] 0.6521739

### Working with the amyloid data

``` r
df_amyloid_mci =
  read_csv("data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |> 
  rename(id = study_id, 
         year_0 = baseline, 
         year_2 = time_2, 
         year_4 = time_4, 
         year_6 = time_6, 
         year_8 = time_8)
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I also needed to excise the first row of the data while importing using
`skip = 1`. I made a copy and removed the extraneous row before
importing. I used the `rename()` function to rename the `study_id`
variable to `id` which will make it easier to compare with
`df_baseline_mci`

### Comparing the two datasets

``` r
## only in baseline
df_only_baseline = 
  anti_join(df_baseline_mci, df_amyloid_mci)
```

    ## Joining with `by = join_by(id)`

``` r
## only in amyloid
df_only_amyloid = 
  anti_join(df_amyloid_mci, df_baseline_mci)
```

    ## Joining with `by = join_by(id)`

``` r
df_baseline_amyloid = 
  inner_join(df_baseline_mci, df_amyloid_mci)
```

    ## Joining with `by = join_by(id)`

I used the `inner_join()` function to join `df_amyloid_mci` and
`df_baseline_mci` by the variable `id`. Based on the resulting 94x11
tibble, it appears that 90 of the participants are shared between the
two datasets (have the same value in the `id` column). The resulting
dataset contains all variables from both `df_amyloid_mci` and
`df_baseline_mci` and all matching observations.

``` r
df_baseline_amyloid |> 
  write.csv("df_baseline_amyloid.csv")
```

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.
